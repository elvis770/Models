{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ich denke es handelt sich hier um ein missvers...</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ich habe tom gerade erst verlassen</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tom versuchte mary nur zu ärgern</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tom hat mir die hand geküsst</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ich wusste dass dir das gefiele</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text language\n",
       "0  ich denke es handelt sich hier um ein missvers...   german\n",
       "1                 ich habe tom gerade erst verlassen   german\n",
       "2                   tom versuchte mary nur zu ärgern   german\n",
       "3                       tom hat mir die hand geküsst   german\n",
       "4                    ich wusste dass dir das gefiele   german"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv('/Users/elvisechefu/Desktop/language detection/languages.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            text\n",
      "language        \n",
      "english   275687\n",
      "french    169693\n",
      "german    199618\n",
      "spanish   118686\n",
      "Total Length of dataset: 763684\n"
     ]
    }
   ],
   "source": [
    "# Get all unique languages values\n",
    "print(df.groupby('language').nunique())\n",
    "print(f\"Total Length of dataset: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text        0\n",
      "language    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 763684 entries, 0 to 763683\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   text      763684 non-null  object\n",
      " 1   language  763684 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 11.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Explore the columns and their types\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode language column\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(df['language'])\n",
    "# df['language'] = le.transform(df['language'])\n",
    "# le.classes_\n",
    "\n",
    "def onehot_encode(df, columns, prefixes):\n",
    "    df = df.copy()\n",
    "    for column, prefix in zip (columns, prefixes):\n",
    "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
    "        df = pd.concat([df , dummies], axis=1)\n",
    "        df = df.drop(column, axis=1)\n",
    "    return df\n",
    "\n",
    "df = onehot_encode(\n",
    "    df,\n",
    "    columns=['language'],\n",
    "    prefixes=['lan']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lan_english</th>\n",
       "      <th>lan_french</th>\n",
       "      <th>lan_german</th>\n",
       "      <th>lan_spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ich denke es handelt sich hier um ein missvers...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ich habe tom gerade erst verlassen</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tom versuchte mary nur zu ärgern</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tom hat mir die hand geküsst</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ich wusste dass dir das gefiele</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  lan_english  lan_french  \\\n",
       "0  ich denke es handelt sich hier um ein missvers...        False       False   \n",
       "1                 ich habe tom gerade erst verlassen        False       False   \n",
       "2                   tom versuchte mary nur zu ärgern        False       False   \n",
       "3                       tom hat mir die hand geküsst        False       False   \n",
       "4                    ich wusste dass dir das gefiele        False       False   \n",
       "\n",
       "   lan_german  lan_spanish  \n",
       "0        True        False  \n",
       "1        True        False  \n",
       "2        True        False  \n",
       "3        True        False  \n",
       "4        True        False  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.drop('text', axis=1)\n",
    "X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan_english</th>\n",
       "      <th>lan_french</th>\n",
       "      <th>lan_german</th>\n",
       "      <th>lan_spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lan_english  lan_french  lan_german  lan_spanish\n",
       "0        False       False        True        False\n",
       "1        False       False        True        False\n",
       "2        False       False        True        False\n",
       "3        False       False        True        False\n",
       "4        False       False        True        False"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ich denke es handelt sich hier um ein missvers...\n",
       "1                   ich habe tom gerade erst verlassen\n",
       "2                     tom versuchte mary nur zu ärgern\n",
       "3                         tom hat mir die hand geküsst\n",
       "4                      ich wusste dass dir das gefiele\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , train_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn pandas dataframe into TensorFlow Dataset\n",
    "#trainset\n",
    "raw_train_dataset = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
    "#testset\n",
    "raw_test_dataset = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches\n",
    "batch_size = 60\n",
    "raw_train_dataset = raw_train_dataset.batch(batch_size)\n",
    "raw_test_dataset = raw_test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b'the only people standing in front of the building are policemen'\n",
      "Label: [ True False False False]\n",
      "Review: b'jusquo\\xc3\\xb9 \\xc3\\xaatesvous pr\\xc3\\xaats \\xc3\\xa0 aller '\n",
      "Label: [False  True False False]\n",
      "Review: b'la cantidad de papel producido por un pa\\xc3\\xads est\\xc3\\xa1 cercanamente relacionado a sus est\\xc3\\xa1ndares culturales'\n",
      "Label: [False False False  True]\n"
     ]
    }
   ],
   "source": [
    "# Print three labels as example\n",
    "for text_batch, label_batch in raw_train_dataset.take(1):\n",
    "    for i in range(3):\n",
    "       print('Review:', text_batch.numpy()[i])\n",
    "       print(\"Label:\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104611"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of unique words in entire dataset\n",
    "from collections import Counter\n",
    "\n",
    "results = Counter()\n",
    "df['text'].str.split().apply(results.update) # Very computer intensive method\n",
    "len(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 50000  # Total words to vectorize\n",
    "sequence_length = 20  # The length of a sentence\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "# Take a smaller sample for adaptation\n",
    "sample_size = 1000  # Choose an appropriate size based on your dataset size\n",
    "subset_for_adaptation = df['text'].sample(n=sample_size)\n",
    "\n",
    "# Adapt to the smaller subset\n",
    "vectorize_layer.adapt(subset_for_adaptation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to vectorize text\n",
    "def vectorize_text(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return tf.dtypes.cast(vectorize_layer(text), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: tf.Tensor(b'the grass is always greener on the other side of the fence', shape=(), dtype=string)\n",
      "Label: tf.Tensor([ True False False False], shape=(4,), dtype=bool)\n",
      "Vectorized review: tf.Tensor(\n",
      "[[  6.   1.  14. 138.   1.  98.   6.   1.   1.  30.   6.   1.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.]], shape=(1, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a batch from the dataset\n",
    "text_batch, label_batch = next(iter(raw_test_dataset))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "\n",
    "print(\"Review:\", first_review)\n",
    "print(\"Label:\", first_label)\n",
    "print(\"Vectorized review:\", vectorize_text(first_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the TextVectorization step to the train and test dataset\n",
    "train_ds = raw_train_dataset.map(lambda x,y: (vectorize_text(x), y))\n",
    "\n",
    "test_ds = raw_test_dataset.map(lambda x ,y: (vectorize_text(x) , y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance measures\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE THE ACTUAL MODEL RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 16)            800016    \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 16)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2176      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 812660 (3.10 MB)\n",
      "Trainable params: 812660 (3.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "embedding_dim = 16\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(max_features + 1, embedding_dim, input_length=20), \n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(128, activation=tf.nn.relu), \n",
    "    layers.Dense(64, activation=tf.nn.relu), \n",
    "    layers.Dense(32, activation=tf.nn.relu),\n",
    "    layers.Dense(4, activation=tf.nn.softmax), \n",
    "    layers.Dropout(0.5),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3819/3819 [==============================] - 9s 2ms/step - loss: nan - accuracy: 0.5072\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8910/8910 [==============================] - 3s 368us/step - loss: 0.0555 - accuracy: 0.9773\n",
      "Loss:  0.055499229580163956\n",
      "Accuracy:  0.9773092269897461\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('my_language_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n",
      "German\n",
      "Certainty: 99.89362359046936%\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "to_predict = [\"Servus was heißt du?\"]\n",
    "\n",
    "to_predict = vectorize_layer(to_predict)\n",
    "prediction = model.predict(to_predict)\n",
    "\n",
    "classes = [\"English\", \"French\", \"German\", \"Spanish\"]\n",
    "\n",
    "highest_prediction = tf.math.argmax(prediction, 1).numpy()\n",
    "\n",
    "print(classes[highest_prediction[0]])\n",
    "print(f\"Certainty: {prediction[0][highest_prediction][0] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "English\n",
      "Certainty: 99.82247948646545%\n"
     ]
    }
   ],
   "source": [
    "#prediction test 2\n",
    "to_predict = [\"Stop that immediate action\", \"I'm going to the movies tonight\"]\n",
    "\n",
    "to_predict = vectorize_layer(to_predict)\n",
    "prediction = model.predict(to_predict)\n",
    "\n",
    "classes = [\"English\", \"French\", \"German\", \"Spanish\"]\n",
    "\n",
    "highest_prediction = tf.math.argmax(prediction, 1).numpy()\n",
    "\n",
    "print(classes[highest_prediction[0]])\n",
    "print(f\"Certainty: {prediction[0][highest_prediction][0] * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicted Language: English, Certainty: 100.00%\n"
     ]
    }
   ],
   "source": [
    "to_predict = [\"i don't undertand what in the world you're saying\"]\n",
    "prediction = model.predict(vectorize_layer(to_predict))\n",
    "print(f\"Predicted Language: {classes[prediction.argmax()]}, Certainty: {100 * prediction.max():.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "Predicted Language: Spanish, Certainty: 58.31%\n"
     ]
    }
   ],
   "source": [
    "to_predict = [\"cállate tu boca huele\"]\n",
    "prediction = model.predict(vectorize_layer(to_predict))\n",
    "print(f\"Predicted Language: {classes[prediction.argmax()]}, Certainty: {100 * prediction.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicted Language: French, Certainty: 81.30%\n"
     ]
    }
   ],
   "source": [
    "to_predict = [\"ton connard pue\"]\n",
    "prediction = model.predict(vectorize_layer(to_predict))\n",
    "print(f\"Predicted Language: {classes[prediction.argmax()]}, Certainty: {100 * prediction.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicted Language: English, Certainty: 99.99%\n"
     ]
    }
   ],
   "source": [
    "to_predict = [\"you are a doppelganger\"]\n",
    "prediction = model.predict(vectorize_layer(to_predict))\n",
    "print(f\"Predicted Language: {classes[prediction.argmax()]}, Certainty: {100 * prediction.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n",
      "Predicted Language: English, Certainty: 99.99%\n"
     ]
    }
   ],
   "source": [
    "to_predict = [\"you are a doppelgänger\"]\n",
    "prediction = model.predict(vectorize_layer(to_predict))\n",
    "print(f\"Predicted Language: {classes[prediction.argmax()]}, Certainty: {100 * prediction.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted Language: English, Certainty: 49.60%\n"
     ]
    }
   ],
   "source": [
    "to_predict = [\"doppelgänger\"]\n",
    "prediction = model.predict(vectorize_layer(to_predict))\n",
    "print(f\"Predicted Language: {classes[prediction.argmax()]}, Certainty: {100 * prediction.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "Predicted Language: French, Certainty: 99.96%\n"
     ]
    }
   ],
   "source": [
    "to_predict = [\"é, je veux toucher tes cheveux s'il te plaît!!!!\"]\n",
    "prediction = model.predict(vectorize_layer(to_predict))\n",
    "print(f\"Predicted Language: {classes[prediction.argmax()]}, Certainty: {100 * prediction.max():.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
